{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vM54r6jlKTII"
   },
   "source": [
    "# Install detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "id": "9_FzH13EjseR",
    "outputId": "ec967368-a1d8-4c19-bbbc-a5095c88a78c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
      "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-onl4h5dc\n",
      "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-onl4h5dc\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (46.1.3)\n",
      "Requirement already satisfied, skipping upgrade: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (0.29.17)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.18.4)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.12.0)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pycocotools: filename=pycocotools-2.0-cp36-cp36m-linux_x86_64.whl size=275264 sha256=70eedf4a1eb943df18684991cfd792ec516a64e5b9781a547fd95d23af5181da\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-10vjhdtt/wheels/90/51/41/646daf401c3bc408ff10de34ec76587a9b3ebfac8d21ca5c3a\n",
      "Successfully built pycocotools\n",
      "Installing collected packages: pycocotools\n",
      "  Found existing installation: pycocotools 2.0.0\n",
      "    Uninstalling pycocotools-2.0.0:\n",
      "      Successfully uninstalled pycocotools-2.0.0\n",
      "Successfully installed pycocotools-2.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U torch torchvision\n",
    "# !pip install git+https://github.com/facebookresearch/fvcore.git\n",
    "# import torch, torchvision\n",
    "# torch.__version__\n",
    "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "b-i4hmGYk1dL",
    "outputId": "888987b4-1099-400c-b4af-d29cb4afa3ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'detectron2_repo'...\n",
      "remote: Enumerating objects: 28, done.\u001b[K\n",
      "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
      "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
      "remote: Total 4689 (delta 9), reused 18 (delta 7), pack-reused 4661\u001b[K\n",
      "Receiving objects: 100% (4689/4689), 2.38 MiB | 2.23 MiB/s, done.\n",
      "Resolving deltas: 100% (3325/3325), done.\n",
      "Obtaining file:///content/detectron2_repo\n",
      "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.2) (1.1.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.2) (7.0.0)\n",
      "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.2) (0.1.7)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.2) (0.8.7)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.2) (1.3.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.2) (3.2.1)\n",
      "Collecting mock\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.2) (4.41.1)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.2) (2.2.1)\n",
      "Requirement already satisfied: fvcore in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.2) (0.1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.2) (0.16.0)\n",
      "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.2) (1.3.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs>=0.1.6->detectron2==0.1.2) (5.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.2) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.2) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.2) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.2) (1.18.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.2) (2.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.2) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.2) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.2) (46.1.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.2) (2.23.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.2) (3.2.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.2) (1.6.0.post3)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.2) (1.7.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.2) (1.12.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.2) (0.34.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.2) (1.28.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.2) (0.9.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.2) (3.10.0)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from fvcore->detectron2==0.1.2) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.2) (1.3.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.2) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.2) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.2) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.2) (2020.4.5.1)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.2) (3.1.1)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.2) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.2) (0.2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.2) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.2) (0.4.8)\n",
      "Installing collected packages: mock, detectron2\n",
      "  Running setup.py develop for detectron2\n",
      "Successfully installed detectron2 mock-4.0.2\n",
      "Collecting numpy==1.17\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/b9/bda9781f0a74b90ebd2e046fde1196182900bd4a8e1ea503d3ffebc50e7c/numpy-1.17.0-cp36-cp36m-manylinux1_x86_64.whl (20.4MB)\n",
      "\u001b[K     |████████████████████████████████| 20.4MB 159kB/s \n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Found existing installation: numpy 1.18.4\n",
      "    Uninstalling numpy-1.18.4:\n",
      "      Successfully uninstalled numpy-1.18.4\n",
      "Successfully installed numpy-1.17.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n",
    "!pip install -e detectron2_repo\n",
    "!pip install numpy==1.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MGFVe1JN8Xn5",
    "outputId": "d8468825-7f94-42a9-cd42-4b334655748b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "\u001b[32m[05/09 16:14:09 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[05/09 16:14:12 d2.data.datasets.coco]: \u001b[0mLoading /content/drive/My Drive/VietAnh/dataset/annotations/data_seg_merged/train_pets.json takes 2.80 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/09 16:14:12 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[05/09 16:14:12 d2.data.datasets.coco]: \u001b[0mLoaded 2937 images in COCO format from /content/drive/My Drive/VietAnh/dataset/annotations/data_seg_merged/train_pets.json\n",
      "\u001b[32m[05/09 16:14:12 d2.data.build]: \u001b[0mRemoved 6 images with no usable annotations. 2931 images left.\n",
      "\u001b[32m[05/09 16:14:12 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|\n",
      "|    cat     | 930          |    dog     | 2001         |\n",
      "|            |              |            |              |\n",
      "|   total    | 2931         |            |              |\u001b[0m\n",
      "\u001b[32m[05/09 16:14:12 d2.data.common]: \u001b[0mSerializing 2931 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[05/09 16:14:12 d2.data.common]: \u001b[0mSerialized dataset takes 3.70 MiB\n",
      "\u001b[32m[05/09 16:14:12 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[05/09 16:14:12 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/09 16:14:34 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[05/09 16:14:34 d2.data.datasets.coco]: \u001b[0mLoaded 734 images in COCO format from /content/drive/My Drive/VietAnh/dataset/annotations/data_seg_merged/val_pets.json\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/09 16:14:34 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[05/09 16:14:34 d2.data.datasets.coco]: \u001b[0mLoaded 734 images in COCO format from /content/drive/My Drive/VietAnh/dataset/annotations/data_seg_merged/val_pets.json\n",
      "\u001b[32m[05/09 16:14:34 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|\n",
      "|    cat     | 247          |    dog     | 486          |\n",
      "|            |              |            |              |\n",
      "|   total    | 733          |            |              |\u001b[0m\n",
      "\u001b[32m[05/09 16:14:34 d2.data.common]: \u001b[0mSerializing 734 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[05/09 16:14:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.94 MiB\n",
      "\u001b[32m[05/09 16:14:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 734 images\n",
      "\u001b[32m[05/09 16:14:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/734. 0.6996 s / img. ETA=0:08:27\n",
      "\u001b[32m[05/09 16:14:54 d2.evaluation.evaluator]: \u001b[0mInference done 18/734. 0.7155 s / img. ETA=0:08:34\n",
      "\u001b[32m[05/09 16:14:59 d2.evaluation.evaluator]: \u001b[0mInference done 25/734. 0.7183 s / img. ETA=0:08:31\n",
      "\u001b[32m[05/09 16:15:04 d2.evaluation.evaluator]: \u001b[0mInference done 33/734. 0.7128 s / img. ETA=0:08:21\n",
      "\u001b[32m[05/09 16:15:09 d2.evaluation.evaluator]: \u001b[0mInference done 40/734. 0.7174 s / img. ETA=0:08:19\n",
      "\u001b[32m[05/09 16:15:15 d2.evaluation.evaluator]: \u001b[0mInference done 48/734. 0.7161 s / img. ETA=0:08:13\n",
      "\u001b[32m[05/09 16:15:20 d2.evaluation.evaluator]: \u001b[0mInference done 55/734. 0.7175 s / img. ETA=0:08:08\n",
      "\u001b[32m[05/09 16:15:25 d2.evaluation.evaluator]: \u001b[0mInference done 62/734. 0.7172 s / img. ETA=0:08:03\n",
      "\u001b[32m[05/09 16:15:30 d2.evaluation.evaluator]: \u001b[0mInference done 69/734. 0.7173 s / img. ETA=0:07:58\n",
      "\u001b[32m[05/09 16:15:35 d2.evaluation.evaluator]: \u001b[0mInference done 76/734. 0.7190 s / img. ETA=0:07:54\n",
      "\u001b[32m[05/09 16:15:40 d2.evaluation.evaluator]: \u001b[0mInference done 83/734. 0.7189 s / img. ETA=0:07:49\n",
      "\u001b[32m[05/09 16:15:46 d2.evaluation.evaluator]: \u001b[0mInference done 90/734. 0.7207 s / img. ETA=0:07:45\n",
      "\u001b[32m[05/09 16:15:51 d2.evaluation.evaluator]: \u001b[0mInference done 97/734. 0.7226 s / img. ETA=0:07:41\n",
      "\u001b[32m[05/09 16:15:56 d2.evaluation.evaluator]: \u001b[0mInference done 104/734. 0.7230 s / img. ETA=0:07:37\n",
      "\u001b[32m[05/09 16:16:01 d2.evaluation.evaluator]: \u001b[0mInference done 111/734. 0.7238 s / img. ETA=0:07:32\n",
      "\u001b[32m[05/09 16:16:06 d2.evaluation.evaluator]: \u001b[0mInference done 118/734. 0.7237 s / img. ETA=0:07:27\n",
      "\u001b[32m[05/09 16:16:11 d2.evaluation.evaluator]: \u001b[0mInference done 125/734. 0.7235 s / img. ETA=0:07:22\n",
      "\u001b[32m[05/09 16:16:16 d2.evaluation.evaluator]: \u001b[0mInference done 132/734. 0.7234 s / img. ETA=0:07:17\n",
      "\u001b[32m[05/09 16:16:22 d2.evaluation.evaluator]: \u001b[0mInference done 139/734. 0.7241 s / img. ETA=0:07:12\n",
      "\u001b[32m[05/09 16:16:27 d2.evaluation.evaluator]: \u001b[0mInference done 147/734. 0.7220 s / img. ETA=0:07:05\n",
      "\u001b[32m[05/09 16:16:32 d2.evaluation.evaluator]: \u001b[0mInference done 154/734. 0.7230 s / img. ETA=0:07:00\n",
      "\u001b[32m[05/09 16:16:37 d2.evaluation.evaluator]: \u001b[0mInference done 161/734. 0.7230 s / img. ETA=0:06:55\n",
      "\u001b[32m[05/09 16:16:43 d2.evaluation.evaluator]: \u001b[0mInference done 169/734. 0.7224 s / img. ETA=0:06:49\n",
      "\u001b[32m[05/09 16:16:49 d2.evaluation.evaluator]: \u001b[0mInference done 177/734. 0.7221 s / img. ETA=0:06:43\n",
      "\u001b[32m[05/09 16:16:54 d2.evaluation.evaluator]: \u001b[0mInference done 184/734. 0.7229 s / img. ETA=0:06:39\n",
      "\u001b[32m[05/09 16:16:59 d2.evaluation.evaluator]: \u001b[0mInference done 191/734. 0.7226 s / img. ETA=0:06:33\n",
      "\u001b[32m[05/09 16:17:04 d2.evaluation.evaluator]: \u001b[0mInference done 198/734. 0.7225 s / img. ETA=0:06:28\n",
      "\u001b[32m[05/09 16:17:10 d2.evaluation.evaluator]: \u001b[0mInference done 206/734. 0.7217 s / img. ETA=0:06:22\n",
      "\u001b[32m[05/09 16:17:15 d2.evaluation.evaluator]: \u001b[0mInference done 214/734. 0.7201 s / img. ETA=0:06:15\n",
      "\u001b[32m[05/09 16:17:20 d2.evaluation.evaluator]: \u001b[0mInference done 221/734. 0.7205 s / img. ETA=0:06:10\n",
      "\u001b[32m[05/09 16:17:26 d2.evaluation.evaluator]: \u001b[0mInference done 228/734. 0.7210 s / img. ETA=0:06:06\n",
      "\u001b[32m[05/09 16:17:31 d2.evaluation.evaluator]: \u001b[0mInference done 235/734. 0.7214 s / img. ETA=0:06:01\n",
      "\u001b[32m[05/09 16:17:36 d2.evaluation.evaluator]: \u001b[0mInference done 242/734. 0.7216 s / img. ETA=0:05:56\n",
      "\u001b[32m[05/09 16:17:41 d2.evaluation.evaluator]: \u001b[0mInference done 249/734. 0.7217 s / img. ETA=0:05:51\n",
      "\u001b[32m[05/09 16:17:47 d2.evaluation.evaluator]: \u001b[0mInference done 257/734. 0.7213 s / img. ETA=0:05:45\n",
      "\u001b[32m[05/09 16:17:52 d2.evaluation.evaluator]: \u001b[0mInference done 264/734. 0.7211 s / img. ETA=0:05:40\n",
      "\u001b[32m[05/09 16:17:57 d2.evaluation.evaluator]: \u001b[0mInference done 271/734. 0.7218 s / img. ETA=0:05:35\n",
      "\u001b[32m[05/09 16:18:02 d2.evaluation.evaluator]: \u001b[0mInference done 278/734. 0.7215 s / img. ETA=0:05:30\n",
      "\u001b[32m[05/09 16:18:07 d2.evaluation.evaluator]: \u001b[0mInference done 285/734. 0.7220 s / img. ETA=0:05:25\n",
      "\u001b[32m[05/09 16:18:12 d2.evaluation.evaluator]: \u001b[0mInference done 292/734. 0.7219 s / img. ETA=0:05:20\n",
      "\u001b[32m[05/09 16:18:18 d2.evaluation.evaluator]: \u001b[0mInference done 300/734. 0.7211 s / img. ETA=0:05:14\n",
      "\u001b[32m[05/09 16:18:23 d2.evaluation.evaluator]: \u001b[0mInference done 308/734. 0.7207 s / img. ETA=0:05:08\n",
      "\u001b[32m[05/09 16:18:29 d2.evaluation.evaluator]: \u001b[0mInference done 315/734. 0.7212 s / img. ETA=0:05:03\n",
      "\u001b[32m[05/09 16:18:34 d2.evaluation.evaluator]: \u001b[0mInference done 322/734. 0.7214 s / img. ETA=0:04:58\n",
      "\u001b[32m[05/09 16:18:39 d2.evaluation.evaluator]: \u001b[0mInference done 329/734. 0.7213 s / img. ETA=0:04:53\n",
      "\u001b[32m[05/09 16:18:44 d2.evaluation.evaluator]: \u001b[0mInference done 336/734. 0.7216 s / img. ETA=0:04:48\n",
      "\u001b[32m[05/09 16:18:49 d2.evaluation.evaluator]: \u001b[0mInference done 343/734. 0.7221 s / img. ETA=0:04:43\n",
      "\u001b[32m[05/09 16:18:54 d2.evaluation.evaluator]: \u001b[0mInference done 350/734. 0.7223 s / img. ETA=0:04:38\n",
      "\u001b[32m[05/09 16:19:00 d2.evaluation.evaluator]: \u001b[0mInference done 358/734. 0.7218 s / img. ETA=0:04:32\n",
      "\u001b[32m[05/09 16:19:05 d2.evaluation.evaluator]: \u001b[0mInference done 366/734. 0.7205 s / img. ETA=0:04:26\n",
      "\u001b[32m[05/09 16:19:10 d2.evaluation.evaluator]: \u001b[0mInference done 373/734. 0.7209 s / img. ETA=0:04:21\n",
      "\u001b[32m[05/09 16:19:16 d2.evaluation.evaluator]: \u001b[0mInference done 381/734. 0.7200 s / img. ETA=0:04:15\n",
      "\u001b[32m[05/09 16:19:22 d2.evaluation.evaluator]: \u001b[0mInference done 389/734. 0.7197 s / img. ETA=0:04:09\n",
      "\u001b[32m[05/09 16:19:27 d2.evaluation.evaluator]: \u001b[0mInference done 396/734. 0.7200 s / img. ETA=0:04:04\n",
      "\u001b[32m[05/09 16:19:32 d2.evaluation.evaluator]: \u001b[0mInference done 404/734. 0.7198 s / img. ETA=0:03:58\n",
      "\u001b[32m[05/09 16:19:38 d2.evaluation.evaluator]: \u001b[0mInference done 411/734. 0.7201 s / img. ETA=0:03:53\n",
      "\u001b[32m[05/09 16:19:43 d2.evaluation.evaluator]: \u001b[0mInference done 418/734. 0.7206 s / img. ETA=0:03:48\n",
      "\u001b[32m[05/09 16:19:48 d2.evaluation.evaluator]: \u001b[0mInference done 425/734. 0.7208 s / img. ETA=0:03:43\n",
      "\u001b[32m[05/09 16:19:54 d2.evaluation.evaluator]: \u001b[0mInference done 433/734. 0.7206 s / img. ETA=0:03:37\n",
      "\u001b[32m[05/09 16:19:59 d2.evaluation.evaluator]: \u001b[0mInference done 440/734. 0.7209 s / img. ETA=0:03:32\n",
      "\u001b[32m[05/09 16:20:04 d2.evaluation.evaluator]: \u001b[0mInference done 447/734. 0.7212 s / img. ETA=0:03:27\n",
      "\u001b[32m[05/09 16:20:09 d2.evaluation.evaluator]: \u001b[0mInference done 454/734. 0.7214 s / img. ETA=0:03:22\n",
      "\u001b[32m[05/09 16:20:15 d2.evaluation.evaluator]: \u001b[0mInference done 462/734. 0.7212 s / img. ETA=0:03:16\n",
      "\u001b[32m[05/09 16:20:20 d2.evaluation.evaluator]: \u001b[0mInference done 469/734. 0.7219 s / img. ETA=0:03:12\n",
      "\u001b[32m[05/09 16:20:26 d2.evaluation.evaluator]: \u001b[0mInference done 477/734. 0.7214 s / img. ETA=0:03:06\n",
      "\u001b[32m[05/09 16:20:31 d2.evaluation.evaluator]: \u001b[0mInference done 484/734. 0.7216 s / img. ETA=0:03:01\n",
      "\u001b[32m[05/09 16:20:36 d2.evaluation.evaluator]: \u001b[0mInference done 491/734. 0.7217 s / img. ETA=0:02:56\n",
      "\u001b[32m[05/09 16:20:42 d2.evaluation.evaluator]: \u001b[0mInference done 499/734. 0.7214 s / img. ETA=0:02:50\n",
      "\u001b[32m[05/09 16:20:48 d2.evaluation.evaluator]: \u001b[0mInference done 507/734. 0.7211 s / img. ETA=0:02:44\n",
      "\u001b[32m[05/09 16:20:53 d2.evaluation.evaluator]: \u001b[0mInference done 515/734. 0.7210 s / img. ETA=0:02:38\n",
      "\u001b[32m[05/09 16:20:58 d2.evaluation.evaluator]: \u001b[0mInference done 522/734. 0.7210 s / img. ETA=0:02:33\n",
      "\u001b[32m[05/09 16:21:04 d2.evaluation.evaluator]: \u001b[0mInference done 530/734. 0.7207 s / img. ETA=0:02:27\n",
      "\u001b[32m[05/09 16:21:09 d2.evaluation.evaluator]: \u001b[0mInference done 538/734. 0.7197 s / img. ETA=0:02:21\n",
      "\u001b[32m[05/09 16:21:15 d2.evaluation.evaluator]: \u001b[0mInference done 546/734. 0.7195 s / img. ETA=0:02:15\n",
      "\u001b[32m[05/09 16:21:20 d2.evaluation.evaluator]: \u001b[0mInference done 553/734. 0.7196 s / img. ETA=0:02:10\n",
      "\u001b[32m[05/09 16:21:25 d2.evaluation.evaluator]: \u001b[0mInference done 560/734. 0.7196 s / img. ETA=0:02:05\n",
      "\u001b[32m[05/09 16:21:30 d2.evaluation.evaluator]: \u001b[0mInference done 567/734. 0.7195 s / img. ETA=0:02:00\n",
      "\u001b[32m[05/09 16:21:35 d2.evaluation.evaluator]: \u001b[0mInference done 574/734. 0.7196 s / img. ETA=0:01:55\n",
      "\u001b[32m[05/09 16:21:40 d2.evaluation.evaluator]: \u001b[0mInference done 581/734. 0.7196 s / img. ETA=0:01:50\n",
      "\u001b[32m[05/09 16:21:45 d2.evaluation.evaluator]: \u001b[0mInference done 588/734. 0.7196 s / img. ETA=0:01:45\n",
      "\u001b[32m[05/09 16:21:50 d2.evaluation.evaluator]: \u001b[0mInference done 595/734. 0.7198 s / img. ETA=0:01:40\n",
      "\u001b[32m[05/09 16:21:56 d2.evaluation.evaluator]: \u001b[0mInference done 602/734. 0.7200 s / img. ETA=0:01:35\n",
      "\u001b[32m[05/09 16:22:01 d2.evaluation.evaluator]: \u001b[0mInference done 610/734. 0.7198 s / img. ETA=0:01:29\n",
      "\u001b[32m[05/09 16:22:07 d2.evaluation.evaluator]: \u001b[0mInference done 618/734. 0.7195 s / img. ETA=0:01:23\n",
      "\u001b[32m[05/09 16:22:12 d2.evaluation.evaluator]: \u001b[0mInference done 625/734. 0.7196 s / img. ETA=0:01:18\n",
      "\u001b[32m[05/09 16:22:18 d2.evaluation.evaluator]: \u001b[0mInference done 632/734. 0.7196 s / img. ETA=0:01:13\n",
      "\u001b[32m[05/09 16:22:23 d2.evaluation.evaluator]: \u001b[0mInference done 639/734. 0.7199 s / img. ETA=0:01:08\n",
      "\u001b[32m[05/09 16:22:28 d2.evaluation.evaluator]: \u001b[0mInference done 646/734. 0.7198 s / img. ETA=0:01:03\n",
      "\u001b[32m[05/09 16:22:33 d2.evaluation.evaluator]: \u001b[0mInference done 653/734. 0.7199 s / img. ETA=0:00:58\n",
      "\u001b[32m[05/09 16:22:38 d2.evaluation.evaluator]: \u001b[0mInference done 660/734. 0.7200 s / img. ETA=0:00:53\n",
      "\u001b[32m[05/09 16:22:43 d2.evaluation.evaluator]: \u001b[0mInference done 667/734. 0.7202 s / img. ETA=0:00:48\n",
      "\u001b[32m[05/09 16:22:49 d2.evaluation.evaluator]: \u001b[0mInference done 674/734. 0.7204 s / img. ETA=0:00:43\n",
      "\u001b[32m[05/09 16:22:54 d2.evaluation.evaluator]: \u001b[0mInference done 682/734. 0.7204 s / img. ETA=0:00:37\n",
      "\u001b[32m[05/09 16:22:59 d2.evaluation.evaluator]: \u001b[0mInference done 689/734. 0.7203 s / img. ETA=0:00:32\n",
      "\u001b[32m[05/09 16:23:05 d2.evaluation.evaluator]: \u001b[0mInference done 697/734. 0.7199 s / img. ETA=0:00:26\n",
      "\u001b[32m[05/09 16:23:10 d2.evaluation.evaluator]: \u001b[0mInference done 705/734. 0.7196 s / img. ETA=0:00:20\n",
      "\u001b[32m[05/09 16:23:15 d2.evaluation.evaluator]: \u001b[0mInference done 712/734. 0.7196 s / img. ETA=0:00:15\n",
      "\u001b[32m[05/09 16:23:21 d2.evaluation.evaluator]: \u001b[0mInference done 719/734. 0.7197 s / img. ETA=0:00:10\n",
      "\u001b[32m[05/09 16:23:26 d2.evaluation.evaluator]: \u001b[0mInference done 726/734. 0.7199 s / img. ETA=0:00:05\n",
      "\u001b[32m[05/09 16:23:31 d2.evaluation.evaluator]: \u001b[0mInference done 733/734. 0.7198 s / img. ETA=0:00:00\n",
      "\u001b[32m[05/09 16:23:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:08:47.310510 (0.723334 s / img per device, on 1 devices)\n",
      "\u001b[32m[05/09 16:23:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:08:44 (0.719803 s / img per device, on 1 devices)\n",
      "\u001b[32m[05/09 16:23:32 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[05/09 16:23:32 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[05/09 16:23:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.57s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.537\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.947\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.539\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.537\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.624\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.625\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.625\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.625\n",
      "\u001b[32m[05/09 16:23:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 53.733 | 94.699 | 53.915 |  nan  |  nan  | 53.733 |\n",
      "\u001b[32m[05/09 16:23:32 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[05/09 16:23:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-----------|:-------|\n",
      "| cat        | 60.585 | dog        | 46.881 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.47s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.691\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.968\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.837\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.692\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.743\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.744\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.744\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.744\n",
      "\u001b[32m[05/09 16:23:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 69.126 | 96.755 | 83.729 |  nan  |  nan  | 69.170 |\n",
      "\u001b[32m[05/09 16:23:33 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[05/09 16:23:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-----------|:-------|\n",
      "| cat        | 67.742 | dog        | 70.510 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bbox',\n",
       "              {'AP': 53.73262470926456,\n",
       "               'AP-cat': 60.58472350025035,\n",
       "               'AP-dog': 46.88052591827877,\n",
       "               'AP50': 94.69874817572581,\n",
       "               'AP75': 53.91497242611355,\n",
       "               'APl': 53.73262470926456,\n",
       "               'APm': nan,\n",
       "               'APs': nan}),\n",
       "             ('segm',\n",
       "              {'AP': 69.12588914956093,\n",
       "               'AP-cat': 67.7416559669871,\n",
       "               'AP-dog': 70.51012233213477,\n",
       "               'AP50': 96.75470733938441,\n",
       "               'AP75': 83.7290259091409,\n",
       "               'APl': 69.169772428465,\n",
       "               'APm': nan,\n",
       "               'APs': nan})])"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount('/content/drive')\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "import os\n",
    "from detectron2.data.datasets import register_coco_instances, register_coco_panoptic_separated\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import json\n",
    "import numpy as np\n",
    "# import some common detectron2 utilities\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "train = \"pets_train\"\n",
    "image_root = \"/content/drive/My Drive/VietAnh/dataset/image\"\n",
    "instances_json = \"/content/drive/My Drive/VietAnh/dataset/annotations/data_seg_merged/train_pets.json\"\n",
    "instances_val_json = \"/content/drive/My Drive/VietAnh/dataset/annotations/data_seg_merged/val_pets.json\"\n",
    "val = \"pets_val\"\n",
    "# val = train\n",
    "register_coco_instances(train, {}, instances_json, image_root)\n",
    "register_coco_instances(val, {}, instances_val_json, image_root)\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/content/detectron2_repo/configs/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")\n",
    "cfg.DATASETS.TRAIN = (train,)\n",
    "cfg.DATASETS.TEST = (val, )   # no metrics implemented for this dataset\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2 # 3 classes (data, fig, hazelnut)\n",
    "cfg.OUTPUT_DIR = \"/content/drive/My Drive/VietAnh/weights\"\n",
    "cfg.INPUT.MASK_FORMAT = 'bitmask'\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.DATASETS.TEST = (val, )\n",
    "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.2\n",
    "cfg.MODEL.RETINANET.NMS_THRESH_TEST = 0.2\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 100\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 10\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(True)\n",
    "predictor = DefaultPredictor(cfg)\n",
    "meta_val = MetadataCatalog.get(val)\n",
    "dicts_val = DatasetCatalog.get(val)\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(val, cfg, False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, val)\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Evaluate.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
